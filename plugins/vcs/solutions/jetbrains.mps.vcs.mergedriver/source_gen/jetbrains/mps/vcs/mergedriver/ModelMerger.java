package jetbrains.mps.vcs.mergedriver;

/*Generated by MPS */

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import java.io.File;
import jetbrains.mps.smodel.persistence.RoleIdsComponent;
import jetbrains.mps.smodel.SModel;
import jetbrains.mps.vcs.ModelUtils;
import java.io.IOException;
import jetbrains.mps.smodel.SModelFqName;
import jetbrains.mps.vcs.diff.merge.MergeContext;
import jetbrains.mps.internal.collections.runtime.Sequence;
import jetbrains.mps.internal.collections.runtime.IWhereFilter;
import jetbrains.mps.vcs.diff.changes.ModelChange;
import jetbrains.mps.internal.collections.runtime.ListSequence;
import jetbrains.mps.smodel.ModelAccess;
import java.io.OutputStream;
import jetbrains.mps.util.FileUtil;

/*package*/ class ModelMerger extends SimpleMerger {
  protected static Log log = LogFactory.getLog(ModelMerger.class);

  /*package*/ ModelMerger() {
  }

  @Override
  protected int mergeFiles(File baseFile, File localFile, File latestFile) {
    System.setProperty("mps.playRefactorings", "false");
    try {
      MergerRoleIdsHandler roleIdsHandler = new MergerRoleIdsHandler();
      RoleIdsComponent.setHandler(roleIdsHandler);

      SModel baseModel;
      SModel localModel;
      SModel latestModel;
      try {
        if (log.isInfoEnabled()) {
          log.info("Reading models...");
        }
        baseModel = ModelUtils.readModel(baseFile);
        if (baseModel == null) {
          throw new Exception("Could not read base model");
        }
        localModel = ModelUtils.readModel(localFile);
        if (localModel == null) {
          throw new Exception("Could not read local model");
        }
        latestModel = ModelUtils.readModel(latestFile);
        if (latestModel == null) {
          throw new Exception("Could not read latest model");
        }
      } catch (IOException e) {
        throw e;
      } catch (Throwable e) {
        if (log.isErrorEnabled()) {
          log.error("Exception while reading models", e);
        }
        return super.mergeFiles(baseFile, localFile, latestFile);
      }

      SModelFqName modelFqName = baseModel.getSModelFqName();
      int baseP = baseModel.getPersistenceVersion();
      int localP = localModel.getPersistenceVersion();
      int latestP = latestModel.getPersistenceVersion();
      if (baseP >= 7 && localP >= 7 && latestP >= 7 || baseP < 7 && localP < 7 && latestP < 7) {
        // ok, can merge 
      } else {
        if (log.isErrorEnabled()) {
          log.error(String.format("%s: Conflicting model persistence versions", modelFqName));
        }
        return super.mergeFiles(baseFile, localFile, latestFile);
      }
      if (!(roleIdsHandler.isConsistent())) {
        if (log.isErrorEnabled()) {
          log.error(String.format("%s: Inconsistent structure ids or import versions", modelFqName));
        }
        return super.mergeFiles(baseFile, localFile, latestFile);
      }

      try {
        if (log.isInfoEnabled()) {
          log.info("Merging " + baseModel.getSModelReference() + "...");
        }
        final MergeContext mergeContext = new MergeContext(baseModel, localModel, latestModel);
        int conflictingChangesCount = Sequence.fromIterable(mergeContext.getAllChanges()).where(new IWhereFilter<ModelChange>() {
          public boolean accept(ModelChange c) {
            return Sequence.fromIterable(mergeContext.getConflictedWith(c)).isNotEmpty();
          }
        }).count();
        if (conflictingChangesCount == 0) {
          if (log.isInfoEnabled()) {
            log.info(String.format("%s: %d changes detected: %d local and %d latest.", modelFqName, Sequence.fromIterable(mergeContext.getAllChanges()).count(), ListSequence.fromList(mergeContext.getMyChangeSet().getModelChanges()).count(), ListSequence.fromList(mergeContext.getRepositoryChangeSet().getModelChanges()).count()));
          }
          mergeContext.getResultModel().setLoading(true);
          Runnable applyAction = new Runnable() {
            public void run() {
              mergeContext.applyChanges(mergeContext.getAllChanges());
            }
          };
          ModelAccess.instance().runReadAction(applyAction);
          if (mergeContext.hasIdsToRestore()) {
            if (log.isInfoEnabled()) {
              log.info(String.format("%s: node id duplication detected, should merge in UI.", modelFqName));
            }
          } else {
            byte[] bytes = ModelUtils.modelToBytes(mergeContext.getResultModel());
            if (log.isInfoEnabled()) {
              log.info(String.format("%s: merged successfully.", modelFqName));
            }
            OutputStream out = null;
            try {
              out = getResultStream(localFile);
              out.write(bytes);
              return MERGED;
            } catch (IOException e) {
              e.printStackTrace();
              return FATAL_ERROR;
            } finally {
              FileUtil.closeFileSafe(out);
            }
          }
        } else {
          if (log.isInfoEnabled()) {
            log.info(String.format("%s: %d changes detected, %d of them are conflicting", modelFqName, Sequence.fromIterable(mergeContext.getAllChanges()).count(), conflictingChangesCount));
          }
        }
      } catch (Throwable e) {
        if (log.isErrorEnabled()) {
          log.error("Exception while merging", e);
        }
        return super.mergeFiles(baseFile, localFile, latestFile);
      }

      return super.mergeFiles(baseFile, localFile, latestFile);
    } catch (IOException e) {
      e.printStackTrace();
      return FATAL_ERROR;
    }
  }
}
